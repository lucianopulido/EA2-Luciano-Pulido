{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pulido_Luciano_ejercicio1.1.2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jqWmvryPEDR"
      },
      "source": [
        "#1 Introducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoK4e_AJMyO3"
      },
      "source": [
        "\n",
        "Suma de vectores usando la GPU usando paralelismo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF-apMtjNhE_"
      },
      "source": [
        "#2 Armado del ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYcR901ZNrjZ"
      },
      "source": [
        "Instala en el cuaderno el módulo CUDA de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iSh-KYdMmYh"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqwN7L6vON5y"
      },
      "source": [
        "#3 Desarrollo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Juw3ROvOezfH"
      },
      "source": [
        "Versión secuencial CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUVmlTxAex7h",
        "outputId": "fc595b23-b799-4a13-d80e-bb204ab4256d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "lista1 = [1,2,3,4,5]\n",
        "lista2 = [1,2,3,4,5]\n",
        "lista3 = [0,0,0,0,0]\n",
        "\n",
        "tiempoInicialFor = datetime.now()\n",
        "for i in range(5):\n",
        "  lista3[i] = lista1[i] + lista2[i]\n",
        "\n",
        "tiempoFinalFor = datetime.now()\n",
        "\n",
        "tiempoFor = tiempoFinalFor.microsecond - tiempoInicialFor.microsecond\n",
        "print(lista3);\n",
        "print(tiempoFor)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 4, 6, 8, 10]\n",
            "76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv6x-T0Ne4HF"
      },
      "source": [
        "Versión con paralelismo GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNXmpn69OTxR"
      },
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from   pycuda.compiler import SourceModule\n",
        "\n",
        "from  datetime import datetime\n",
        "import numpy\n",
        "\n",
        "n=50\n",
        "lista1 = numpy.random.randn(n)\n",
        "lista1 = lista1.astype(numpy.float32())\n",
        "\n",
        "lista2 = numpy.random.rand(n)\n",
        "lista2 = lista2.astype(numpy.float32())\n",
        "\n",
        "lista3 = numpy.empty_like(lista1)\n",
        "\n",
        "# CPU - reservo la memoria GPU\n",
        "lista1_gpu = cuda.mem_alloc(lista1.nbytes)\n",
        "lista2_gpu = cuda.mem_alloc(lista2.nbytes)\n",
        "\n",
        "# GPU - copio la memoria al GPU\n",
        "cuda.memcpy_htod(lista1_gpu,lista1)\n",
        "cuda.memcpy_htod(lista2_gpu,lista2)\n",
        "\n",
        "#CPU - Defino la funcion kernel que ejecutará en GPU\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void kernel_sumaListas(int n, float *plista1 , float *plista2)\n",
        "{\n",
        "    int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "    if(idx<n)\n",
        "    {\n",
        "      plista2[idx] += plista1[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "# CPU - Genero la funcion kernel\n",
        "kernel = module.get_function(\"kernel_sumaListas\")\n",
        "\n",
        "tiempoInicialGpu = datetime.now()\n",
        "\n",
        "# GPU - Ejecuto el kernel\n",
        "dim_hilo = 256\n",
        "dim_bloque = numpy.int((n+dim_hilo-1)/dim_hilo)\n",
        "print(\"Thread: \",dim_hilo, \"Bloque: \", dim_bloque)\n",
        "\n",
        "kernel(numpy.int32(n),lista1_gpu,lista2_gpu, block = (dim_hilo,1,1),grid = (dim_bloque,1,1))\n",
        "\n",
        "tiempoFinalGpu = datetime.now()\n",
        "#GPU - copio el resultado desde la memoria de la GPU\n",
        "cuda.memcpy_dtoh(lista3,lista2_gpu)\n",
        "\n",
        "tiempoFinal = tiempoFinalGpu.microsecond - tiempoInicialGpu.microsecond\n",
        "print(lista3);\n",
        "print(\"Tiempo total: \",tiempoFinal,\"[ms]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmscJ_ThPKyk"
      },
      "source": [
        "#4 Tabla de pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7vG__4lPOAU"
      },
      "source": [
        "#5 Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unZzvgJHPQ2J"
      },
      "source": [
        "#6 Bibliografia"
      ]
    }
  ]
}