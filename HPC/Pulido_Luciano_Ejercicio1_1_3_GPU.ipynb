{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pulido_Luciano_Ejercicio1_1_3_GPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OeRknPGL5j9"
      },
      "source": [
        "#1 Introducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XID43y6qMTiJ"
      },
      "source": [
        "En el siguiente cuaderno se realiza el algoritmo que obtiene la matriz transpuesta de una matriz (su orden se ingresa por parametro) de números flotantes aplicando paralelismo y utilizando el GPGPU.\n",
        "\n",
        "El algoritmo de este cuadernos se basa en, valga la redundancia, del algortimo para transponer una matriz proveniente del algebra lineal[3]\n",
        "\n",
        "El objetivo es comparar los tiempos de ejecución de ambas versiones del algoritmo que obtiene la matriz transpuesta, utilizando el lenguaje python [2],la plataforma colab [1] y CUDA [4,5]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws8FMRkOL1fa"
      },
      "source": [
        "#2 Preparado del ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFJCk97VzFeH"
      },
      "source": [
        "Instala en el cuaderno el módulo CUDA de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvA7Usust8hP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4553545c-347a-4590-9759-61cef80726f9"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 8.5MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=621228 sha256=a4fd66bbd14df96e984ca5d363f5232c3dd1ec0807c6868240d50dd179999deb\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=b229c6d1185706ec703069f4c906dbfbeeb28e1f076aedb6585e38868e7432d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDY75qvrMBJy"
      },
      "source": [
        "#3 Desarrollo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycSUvt1HMPGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b76375e-2f0d-467b-9cb8-19436416b851"
      },
      "source": [
        "#@title Parametros { vertical-output: true, display-mode: \"both\" }\n",
        "ordenMatriz =  5#@param {type:\"number\"}\n",
        "try:\n",
        "  from datetime import datetime\n",
        "  tiempo_total = datetime.now()\n",
        "\n",
        "  import pycuda.driver as cuda\n",
        "  import pycuda.autoinit\n",
        "  from   pycuda.compiler import SourceModule\n",
        "  import numpy\n",
        "\n",
        "  # Definición de función que transforma el tiempo en  milisegundos\n",
        "  tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "  \n",
        "  # CPU - Defino la memoria de las matrices en cpu.\n",
        "  matriz = numpy.random.random((ordenMatriz,ordenMatriz))\n",
        "  matriz = matriz.astype(numpy.float32())\n",
        "\n",
        "  matrizT = numpy.empty_like(matriz)\n",
        "\n",
        "  # CPU - reservo la memoria GPU.\n",
        "  matrizGpu = cuda.mem_alloc(matriz.nbytes)\n",
        "  matriztGpu = cuda.mem_alloc(matrizT.nbytes)\n",
        "\n",
        "  # GPU - Copio la memoria al GPU.\n",
        "  cuda.memcpy_htod(matrizGpu,matriz)\n",
        "  cuda.memcpy_htod(matriztGpu,matrizT)\n",
        "\n",
        "  #CPU - Defino la funcion kernel que ejecutará en GPU\n",
        "  module = SourceModule(\"\"\"\n",
        "  __global__ void transponer(int n, float *matriz ,float *matrizT ,float *pvector1)\n",
        "  {\n",
        "      int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "      int idy = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "      \n",
        "      \n",
        "\n",
        "      if(idx<n && idy<n)\n",
        "      {\n",
        "        matrizT[idy*n+idx] = matriz[idx*n+idy];\n",
        "      }\n",
        "  }\n",
        "\n",
        "  \"\"\")\n",
        "\n",
        "  kernel = module.get_function(\"transponer\")\n",
        "\n",
        "  tiempo_gpu = datetime.now()\n",
        "\n",
        "  dim_hilo_x = 16\n",
        "  dim_bloque_x = numpy.int( (ordenMatriz+dim_hilo_x-1) / dim_hilo_x )\n",
        "\n",
        "  dim_hilo_y = 16\n",
        "  dim_bloque_y = numpy.int( (ordenMatriz+dim_hilo_y-1) / dim_hilo_y )\n",
        "\n",
        "  print( \"Thread x: \", dim_hilo_x, \", Bloque x:\", dim_bloque_x )\n",
        "  print( \"Thread y: \", dim_hilo_y, \", Bloque y:\", dim_bloque_y )\n",
        "\n",
        "  kernel( numpy.int32(ordenMatriz), matrizGpu ,matriztGpu, block=( dim_hilo_x, dim_hilo_y, 1 ),grid=(dim_bloque_x, dim_bloque_y,1) )\n",
        "\n",
        "  tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "  cuda.memcpy_dtoh(matrizT,matriztGpu)\n",
        "\n",
        "  tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "  # CPU - Informo el resultado.\n",
        "  print(\"matriz original: \")\n",
        "  print(matriz)\n",
        "  print(\"\")\n",
        "  print(\"matriz transpuesta: \")\n",
        "  print(matrizT)\n",
        "  print(\"\")\n",
        "  print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "  print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu ), \"[ms]\" )\n",
        "except ModuleNotFoundError :\n",
        "      print(\"No se compilo el código del armado del ambiente\")\n",
        "      print(\"Compile el armado del ambiente y vuelva a intentarlo\")\n",
        "except ValueError :\n",
        "  print(\"se ingreso un orden (tamaño de la matriz) menor a 0\")\n",
        "  print(\"ingrese un orden mayor a 0\")\n",
        "except pycuda.driver.LogicError:\n",
        "  print(\"Ha ingresado un orden de la matriz igual a 0 y CUDA no puede reservar una matriz de tamaño 0\")\n",
        "  print(\"ingrese un orden para la matriz mayor a 0\")\n",
        "      \n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread x:  16 , Bloque x: 1\n",
            "Thread y:  16 , Bloque y: 1\n",
            "matriz original: \n",
            "[[0.83960265 0.53017443 0.36653844 0.94952106 0.2333136 ]\n",
            " [0.30120647 0.60115373 0.39224187 0.9295438  0.50992084]\n",
            " [0.6406561  0.42474523 0.8849957  0.63515824 0.6867062 ]\n",
            " [0.24683534 0.07154205 0.899879   0.12797351 0.5175436 ]\n",
            " [0.7793347  0.08413104 0.09035027 0.99284047 0.79426026]]\n",
            "\n",
            "matriz transpuesta: \n",
            "[[0.83960265 0.30120647 0.6406561  0.24683534 0.7793347 ]\n",
            " [0.53017443 0.60115373 0.42474523 0.07154205 0.08413104]\n",
            " [0.36653844 0.39224187 0.8849957  0.899879   0.09035027]\n",
            " [0.94952106 0.9295438  0.63515824 0.12797351 0.99284047]\n",
            " [0.2333136  0.50992084 0.6867062  0.5175436  0.79426026]]\n",
            "\n",
            "Tiempo CPU:  1.623 [ms]\n",
            "Tiempo GPU:  0.304 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edYF9HRNMBeL"
      },
      "source": [
        "#4 Tabla de pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvBooRW7MVbF"
      },
      "source": [
        "\n",
        " Procesador | Funciòn | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tamaño del vector desde Colab.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  numpy.random.randn( ordenMatriz ) | Inicializa las matrices\n",
        "**GPU**  |  cuda.mem_alloc()      | Reserva la memoria en GPU.\n",
        "**GPU**  |  cuda.memcpy_htod()    | Copia las memorias desde el CPU al GPU.\n",
        "CPU      |  SourceModule()        | Define el código del kernel donde se transpone la matriz\n",
        "CPU      |  module.get_function() | Genera la función del kernel GPU\n",
        "CPU      |  dim_hilo/dim_bloque   | Calcula las dimensiones.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU\n",
        "CPU      |  cuda.memcpy_dtoh( )   | Copia el resultado desde GPU memoria A a CPU.\n",
        "CPU      |  print()               | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIi2z69MMBvT"
      },
      "source": [
        "#5 Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmZIB03dMV4o"
      },
      "source": [
        "En este ejercicio que se basa en el algortimo que obtiene la matriz transpuesta de una matriz, los tiempos de ejecución resultaron más eficientes utilizando paralelismo utilizando el GPGPU porque al ser un algoritmo donde se puede mover grandes cantidades de datos ya que los tiempos de ejecución  son pequeños en comparación con la versión secuencial porque evitamos cualquier tipo de bucles, por la enorme cantidad de hilos que nos ofrece la GPU que nos permiten evitar estos bucles ya que podemos acceder de manera directa a los datos correspondientes.\n",
        "\n",
        "Para poder sacar estas conclusiones tome 20 muestras del algoritmo en la version secuencial (CPU) y la versión con paralelismo (CPU-GPU) con un número de elementos igual a 100 y obtuve los siguientes promedios:\n",
        "\n",
        "Promedio de tiempo ejercicio 2 secuencial: 12.224,4 ms\n",
        "\n",
        "Promedio de tiempo de Bucle ejercicio 2: 11.497,4 ms\n",
        "\n",
        "Promedio de tiempo CPU ejercicio 2 paralelismo: 2.407 ms \n",
        "\n",
        "Promedio de tiempo GPU ejercicio 2 paralelismo: 0,2676 ms\n",
        "\n",
        "\n",
        "Como vemos en los resultados obtenidos, el tiempo total(CPU) en la versión con paralelismo (GPGPU) es menor al tiempo equivalente que es el tiempo de CPU, en la versión secuencial.\n",
        "\n",
        "Por este motivo puedo decir que en los ejercicios donde tenemos que mover grandes cantidades de datos, utilizar paralelismo con (GPGPU) es más optimo porque como mencione anteriormente nos permite acceder de manera directa a los datos correspondientes y nos permite evitar el uso de bucles permitiendonos de esta manera ahorrar mucho tiempo de ejecución.\n",
        "\n",
        "Para continuar este ejercicio tanto en la versión secuencial como en la versión con paralelismo se podría hacer que hagamos 2 movimientos de datos al mismo tiempo y ahorrar la mitad del tiempo, es decir, por ejemplo cuando se va a copiar un valor de la matriz de la posicion [ i ][ j ] a la posición [ j ][ i ],antes de hacer esto, se podria copiar el valor de la posicion [ j ][ i ] en una variable auxiliar y copiar el valor en la posicion [ i ][ j ] luego de que el valor de esta posición haya sido copiado en la posición [ j ][ i ], para poder asi, reducir el tiempo de ejecución a la mitad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDS-ZLNMB8t"
      },
      "source": [
        "#6 Bibliografia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEnO2YVKMWZw"
      },
      "source": [
        "[1] MARKDOWN SYNTAX Colab:[PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "[2] Introducción a Python: [pagina colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb)\n",
        "\n",
        "[3] Función de transponer matriz: [WEB](https://github.com/lucianopulido/EA2-Luciano-Pulido/blob/master/Bibliografia/Ejercicio%202/Fundamentos%20de%20m%C3%A9todos%20matem%C3%A1ticos%20para%20f%C3%ADsica%20e%20ingenier%C3%ADa%20.pdf)\n",
        "\n",
        "[4] Documentación PyCUDA: [WEB](https://documen.tician.de/pycuda/index.html)\n",
        "\n",
        "[5] Repositorio de PyCUDA: [WEB](https://pypi.org/project/pycuda/)"
      ]
    }
  ]
}